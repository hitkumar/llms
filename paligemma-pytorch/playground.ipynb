{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "output": {
          "id": 380457115111251,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "import gc\n",
        "# del variables\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from modeling_gemma import PaliGemmaForConditionalGeneration, PaliGemmaConfig\n",
        "from transformers import AutoTokenizer\n",
        "import json\n",
        "import glob\n",
        "from safetensors import safe_open\n",
        "from typing import Tuple\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from processing_paligemma import PaliGemmaProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "output": {
          "id": 391256877366326,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ae49135364c4d1a9a5adbcd8b83fbf1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "output": {
          "id": 1271736454259648,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor([12]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "output": {
          "id": 3473029716333648,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([12, 13, 14, 15])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_tokens = [torch.tensor([12]), torch.tensor([13]), torch.tensor([14]), torch.tensor([15])]\n",
        "generated_tokens = torch.cat(generated_tokens, dim=-1)\n",
        "generated_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import load_hf_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = \"/home/htkumar/paligemma-3b-pt-224\"\n",
        "device = 'cuda'\n",
        "model, tokenizer = load_hf_model(model_path, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.to(device).eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "output": {
          "id": 1057961358712261,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "256 224\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "16.0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(model.config.vision_config.num_image_tokens, model.config.vision_config.image_size)\n",
        "224 / 14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "output": {
          "id": 413479278433644,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config.text_config.hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_image_tokens = model.config.vision_config.num_image_tokens\n",
        "image_size = model.config.vision_config.image_size\n",
        "processor = PaliGemmaProcessor(tokenizer, num_image_tokens, image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from inference import test_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# image_file_path='/home/htkumar/llms/paligemma-pytorch/beans_1000_leaf.jpeg'\n",
        "# prompt='This leaf is '\n",
        "# image = Image.open(image_file_path)\n",
        "# model_inputs = processor([prompt], [image])\n",
        "# model_inputs['input_ids'].dtype, model_inputs['pixel_values'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "output": {
          "id": 1201774661047420,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.int64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the shape of the leaf is leaf\n"
          ]
        }
      ],
      "source": [
        "test_inference(\n",
        "    model=model,\n",
        "    processor=processor,\n",
        "    prompt='the shape of the leaf is ',\n",
        "    image_file_path='/home/htkumar/llms/paligemma-pytorch/beans_1000_leaf.jpeg',\n",
        "    max_tokens_to_generate=10,\n",
        "    device=device,\n",
        "    temperature=0.0,\n",
        "    top_p=0.95,\n",
        "    do_sample=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = tokenizer([\"How are you doing today?\", \"Hey there\"], return_tensors='pt', padding='longest', truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "output": {
          "id": 917542690237840,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{'b': 2, **a}['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "output": {
          "id": 883579503695754,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "output": {
          "id": 894823959237124,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "257152"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "output": {
          "id": 1699979230856413,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<bos>', '<eos>', '<unk>', '<pad>', '<image>']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.all_special_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "output": {
          "id": 529749286483160,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([v for v in tokenizer.get_vocab() if \"<loc\" in v])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "output": {
          "id": 8377574608998431,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the dataset since beans couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'default' at /home/htkumar/.cache/huggingface/datasets/beans/default/0.0.0/27aa014ce09b193e1a6f58112d4a66e0eddb69c5 (last modified on Sat Sep 14 14:21:10 2024).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1034\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"beans\", split=\"train\")\n",
        "print(len(ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds[1000]['image'].save('/home/htkumar/llms/paligemma-pytorch/beans_1000_leaf.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "output": {
          "id": 1338145523839827,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 500, 3)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = Image.open('/home/htkumar/llms/paligemma-pytorch/beans_1000_leaf.jpeg')\n",
        "np.array(image).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "output": {
          "id": 1062410898667250,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PIL.JpegImagePlugin.JpegImageFile"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from processing_paligemma import process_images, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "output": {
          "id": 1627139407843564,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 500, 3)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(image).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "output": {
          "id": 1722651011906782,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 244, 244)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "process_images([image], size=(244, 244), rescale_factor=1 / 255.0, image_mean=IMAGENET_STANDARD_MEAN, image_std=IMAGENET_STANDARD_STD)[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "ename": "ConnectionError",
          "evalue": "Couldn't reach 'ILSVRC/imagenet-1k' on the Hub (ConnectionError)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n",
            "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Image\n",
            "\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset\u001b[49m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mILSVRC/imagenet-1k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m,\u001b[49m \u001b[49msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m~/.conda/envs/gpt-2/lib/python3.10/site-packages/datasets/load.py:2606\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n",
            "\u001b[1;32m   2601\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n",
            "\u001b[1;32m   2602\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n",
            "\u001b[1;32m   2603\u001b[0m )\n",
            "\u001b[1;32m   2605\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n",
            "\u001b[0;32m-> 2606\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder\u001b[49m(\u001b[49m\n",
            "\u001b[1;32m   2607\u001b[0m     \u001b[49mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mpath\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2608\u001b[0m     \u001b[49mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mname\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2609\u001b[0m     \u001b[49mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mdata_dir\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2610\u001b[0m     \u001b[49mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mdata_files\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2611\u001b[0m     \u001b[49mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mcache_dir\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2612\u001b[0m     \u001b[49mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mfeatures\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2613\u001b[0m     \u001b[49mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mdownload_config\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2614\u001b[0m     \u001b[49mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mdownload_mode\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2615\u001b[0m     \u001b[49mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mrevision\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2616\u001b[0m     \u001b[49mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtoken\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2617\u001b[0m     \u001b[49mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mstorage_options\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2618\u001b[0m     \u001b[49mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrust_remote_code\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2619\u001b[0m     \u001b[49m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mname\u001b[49m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m,\u001b[49m\n",
            "\u001b[1;32m   2620\u001b[0m     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49mconfig_kwargs\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2621\u001b[0m \u001b[49m)\u001b[49m\n",
            "\u001b[1;32m   2623\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n",
            "\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
            "\n",
            "File \u001b[0;32m~/.conda/envs/gpt-2/lib/python3.10/site-packages/datasets/load.py:2277\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n",
            "\u001b[1;32m   2275\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n",
            "\u001b[1;32m   2276\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n",
            "\u001b[0;32m-> 2277\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m dataset_module_factory\u001b[49m(\u001b[49m\n",
            "\u001b[1;32m   2278\u001b[0m     \u001b[49mpath\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2279\u001b[0m     \u001b[49mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mrevision\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2280\u001b[0m     \u001b[49mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mdownload_config\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2281\u001b[0m     \u001b[49mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mdownload_mode\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2282\u001b[0m     \u001b[49mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mdata_dir\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2283\u001b[0m     \u001b[49mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mdata_files\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2284\u001b[0m     \u001b[49mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mcache_dir\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2285\u001b[0m     \u001b[49mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrust_remote_code\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2286\u001b[0m     \u001b[49m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m_require_default_config_name\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2287\u001b[0m     \u001b[49m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m(\u001b[49mconfig_kwargs\u001b[49m)\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   2288\u001b[0m \u001b[49m)\u001b[49m\n",
            "\u001b[1;32m   2289\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n",
            "\u001b[1;32m   2290\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
            "\n",
            "File \u001b[0;32m~/.conda/envs/gpt-2/lib/python3.10/site-packages/datasets/load.py:1923\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n",
            "\u001b[1;32m   1918\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n",
            "\u001b[1;32m   1919\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n",
            "\u001b[1;32m   1920\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m   1921\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m   1922\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;32m-> 1923\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n",
            "\u001b[1;32m   1926\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m   1927\u001b[0m     )\n",
            "\n",
            "File \u001b[0;32m~/.conda/envs/gpt-2/lib/python3.10/site-packages/datasets/load.py:1854\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n",
            "\u001b[1;32m   1843\u001b[0m     dataset_info \u001b[38;5;241m=\u001b[39m hf_api\u001b[38;5;241m.\u001b[39mdataset_info(\n",
            "\u001b[1;32m   1844\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mpath,\n",
            "\u001b[1;32m   1845\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n",
            "\u001b[1;32m   1846\u001b[0m         token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken,\n",
            "\u001b[1;32m   1847\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100.0\u001b[39m,\n",
            "\u001b[1;32m   1848\u001b[0m     )\n",
            "\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n",
            "\u001b[1;32m   1850\u001b[0m     OfflineModeIsEnabled,\n",
            "\u001b[1;32m   1851\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectTimeout,\n",
            "\u001b[1;32m   1852\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError,\n",
            "\u001b[1;32m   1853\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[0;32m-> 1854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hub (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[1;32m   1856\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a gated dataset on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\n",
            "\u001b[0;31mConnectionError\u001b[0m: Couldn't reach 'ILSVRC/imagenet-1k' on the Hub (ConnectionError)"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, Image\n",
        "dataset = load_dataset(\"ILSVRC/imagenet-1k\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = \"/home/htkumar/paligemma-3b-pt-224\"\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path, padding_side=\"right\")\n",
        "assert tokenizer.padding_side == \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.encode(\"How are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.max_len_single_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "safetensor_files = glob.glob(os.path.join(model_path, \"*.safetensors\"))\n",
        "safetensor_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tensors = {}\n",
        "for safetensors_file in safetensor_files:\n",
        "    with safe_open(safetensors_file, framework=\"pt\", device='cpu') as f:\n",
        "        for key in f.keys():\n",
        "            tensors[key] = f.get_tensor(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model config\n",
        "with open(os.path.join(model_path, \"config.json\"), \"r\") as f:\n",
        "    model_config_file = json.load(f)\n",
        "    config = PaliGemmaConfig(**model_config_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = PaliGemmaForConditionalGeneration(config).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_state_dict(tensors, strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model.load_state_dict??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.tie_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.language_model.model.embed_tokens.weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = torch.tensor([1, 2, 3, 4, 5])\n",
        "mask = torch.tensor([False, True, False, True, False])\n",
        "source = torch.tensor([10, 20])\n",
        "\n",
        "result = target.masked_scatter(mask, source)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_mask = torch.full(\n",
        "    (4, 12), fill_value=1\n",
        ")\n",
        "attention_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_mask.cumsum(-1)[:, -1].dim()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(attention_mask.cumsum(-1)).masked_fill_((attention_mask == 0), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_size, hidden_state = 10000, 256\n",
        "lm_head = nn.Linear(hidden_state, vocab_size)\n",
        "embed_tokens = nn.Embedding(vocab_size, hidden_state)\n",
        "lm_head.weight.shape, embed_tokens.weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.equal(lm_head.weight, embed_tokens.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lm_head.weight = embed_tokens.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.equal(lm_head.weight, embed_tokens.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base, dim = 1000, 128\n",
        "inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
        "inv_freq.shape, inv_freq.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inv_freq_expanded = inv_freq[None, :, None]\n",
        "inv_freq_expanded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bs, seq_len, n_heads = 2, 10, 4\n",
        "position_ids = torch.cat([torch.arange(seq_len)[None, :] for _ in range(bs)], dim=0)\n",
        "position_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "position_ids_expanded = position_ids[:, None, :].float()\n",
        "position_ids_expanded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freqs = (inv_freq_expanded @ position_ids_expanded).transpose(1, 2)\n",
        "freqs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = torch.ones(bs, n_heads, seq_len, dim)\n",
        "q.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x1 = q[..., :q.shape[-1] // 2]\n",
        "x2 = q[..., q.shape[-1] // 2:]\n",
        "x1.shape, x2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.cat((-x2, x1), dim=-1)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freqs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "emb = torch.cat((freqs, freqs), dim=-1)\n",
        "emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cos = emb.cos()\n",
        "cos.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cos = cos.unsqueeze(1)\n",
        "cos.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rotate_half(x):\n",
        "    x1 = x[..., :x.shape[-1] // 2]\n",
        "    x2 = x[..., x.shape[-1] // 2:]\n",
        "    return torch.cat((-x2, x1), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rotate_half(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.arange(10).expand(1, -1)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_positions = 100\n",
        "emb_dim = 128\n",
        "B = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "emb_layer = nn.Embedding(num_positions, emb_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_output = torch.randn(B, num_positions, emb_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "position_ids = torch.arange(num_positions)\n",
        "position_emb = emb_layer(position_ids)\n",
        "position_emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_1 = conv_output + position_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_2 = conv_output + emb_layer(position_ids.expand(1, -1))\n",
        "out_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.equal(out_1, out_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B, num_heads, seq_len, emb_dim = 4, 2, 10, 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attn_scores = torch.randn(B, num_heads, seq_len, seq_len)\n",
        "values = torch.randn(B, num_heads, seq_len, emb_dim // num_heads)\n",
        "attn_scores.shape, values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out = attn_scores @ values\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "act = torch.ones(B, seq_len, emb_dim)\n",
        "act.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "act.mean(-1, keepdim=True).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "6722272a-6af9-4944-b1b3-6cfb3ad11568",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "bento_kernel_default"
    },
    "language_info": {
      "name": "python"
    }
  }
}
