{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1515589745705497,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torchvision as tv\n",
    "import torchvision.transforms.functional as tvf\n",
    "from torchvision import io\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from triton_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Cute_dog.jpg/1600px-Cute_dog.jpg?20140729055059'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_img = Path('puppy.jpg')\n",
    "# if not path_img.exists():\n",
    "#     urlretrieve(url, path_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 887867063530455,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "img_local_path = \"/home/htkumar/llms/triton_kernels/puppy.jpg\"\n",
    "img = io.read_image(img_local_path)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 569465662706307,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "img[:2, :3, :4].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(x, figsize=(4, 3), **kwargs):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "    if len(x.shape) == 3:\n",
    "        x = x.permute(1, 2, 0)\n",
    "    plt.imshow(x.cpu(), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1779771179491068,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "img = tvf.resize(img, 150, antialias=True)\n",
    "ch, h, w = img.shape\n",
    "ch, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 3898693370275578,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_0 = torch.tensor([2, 3])\n",
    "offset_1 = torch.tensor([4, 5])\n",
    "offset_0[:, None].shape, offset_1[None, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7 * offset_0[:, None] + offset_1[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdiv(a, b): return (a + b - 1) // b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def rgb2grey_k(x_ptr, out_ptr, h, w, bs0: tl.constexpr, bs1: tl.constexpr):\n",
    "    pid_0 = tl.program_id(0)\n",
    "    pid_1 = tl.program_id(1)\n",
    "\n",
    "    offs_0 = pid_0 * bs0 + tl.arange(0, bs0)\n",
    "    offs_1 = pid_1 * bs1 + tl.arange(0, bs1)\n",
    "    offs = w * offs_0[:, None] + offs_1[None, :]\n",
    "\n",
    "    mask_0 = offs_0 < h\n",
    "    mask_1 = offs_1 < w\n",
    "    mask = mask_0[:, None]  & mask_1[None, :]\n",
    "\n",
    "    r = tl.load(x_ptr + 0*h*w + offs, mask)\n",
    "    g = tl.load(x_ptr + 1*h*w + offs, mask)\n",
    "    b = tl.load(x_ptr + 2*h*w + offs, mask)\n",
    "\n",
    "    out = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    tl.store(out_ptr + offs, out, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2grey(x, bs):\n",
    "    c,h,w = x.shape\n",
    "    out = torch.empty((h, w), device=x.device, dtype=x.dtype)\n",
    "\n",
    "    grid = lambda meta: (triton.cdiv(h, meta['bs0']), triton.cdiv(w, meta['bs1']))\n",
    "    rgb2grey_k[grid](x, out, h, w, bs0=bs[0], bs1=bs[1])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_img = rgb2grey(img.to('cuda'), bs=(32, 32)).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(grey_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [3, 4, 5]\n",
    "])\n",
    "print(a.shape)\n",
    "a.stride(0), a.stride(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def naive_matmul_k(\n",
    "    a_ptr, b_ptr, c_ptr,\n",
    "    m, n, k,\n",
    "    stride_am, stride_ak,\n",
    "    stride_bk, stride_bn,\n",
    "    stride_cm, stride_cn,\n",
    "    bm: tl.constexpr, bn: tl.constexpr, bk: tl.constexpr\n",
    "):\n",
    "    pid_m, pid_n = tl.program_id(0), tl.program_id(1)\n",
    "    rm = get_1d_offset(bm, pid_m)\n",
    "    rn = get_1d_offset(bn, pid_n)\n",
    "    # TODO: do we need rk\n",
    "    rk = get_1d_offset(bk, 0)\n",
    "    offs_a = a_ptr + get_2d_offset(rm, rk, stride_am, stride_ak)\n",
    "    offs_b = b_ptr + get_2d_offset(rk, rn, stride_bk, stride_bn)\n",
    "\n",
    "    acc = tl.zeros((bm, bn), dtype=tl.float32)\n",
    "    for _ in range(0, k, bk):\n",
    "        mask_a = get_2d_mask(rm, rk, m, k)\n",
    "        mask_b = get_2d_mask(rk, rn, k, n)\n",
    "\n",
    "        a = tl.load(offs_a, mask=mask_a)\n",
    "        b = tl.load(offs_b, mask=mask_b)\n",
    "        acc += tl.dot(a, b)\n",
    "\n",
    "        offs_a += bk * stride_ak\n",
    "        offs_b += bk * stride_bk\n",
    "\n",
    "    c = c_ptr + get_2d_offset(rm, rn, stride_cm, stride_cn)\n",
    "    mask = get_2d_mask(rm, rn, m, n)\n",
    "    tl.store(c, acc, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def matmul(a, b, matmul_k_fn, bs=16, group_sz=None):\n",
    "    check_tensors_gpu_ready(a, b)\n",
    "    assert a.shape[1] == b.shape[0]\n",
    "    (m, k), (_, n) = a.shape, b.shape\n",
    "\n",
    "    c = torch.zeros((m, n), device=a.device, dtype=torch.float16)\n",
    "    grid = lambda meta: (triton.cdiv(m, meta[\"bm\"]), triton.cdiv(n, meta[\"bn\"]))\n",
    "    naive_matmul_k[grid](\n",
    "        a, b, c, m, n, k,\n",
    "        a.stride(0), a.stride(1),\n",
    "        b.stride(0), b.stride(1),\n",
    "        c.stride(0), c.stride(1),\n",
    "        bm=bs, bn=bs, bk=bs\n",
    "    )\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_matmul = partial(matmul, matmul_k_fn=naive_matmul_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((3, 4), dtype=torch.float32, device='cuda')\n",
    "b = torch.ones((4, 5), dtype=torch.float32, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(128)\n",
    "a = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n",
    "b = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n",
    "triton_output = naive_matmul(a, b)\n",
    "pytorch_output = a@b\n",
    "torch.allclose(triton_output, pytorch_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def naive_matmul_k2(\n",
    "    a_ptr, b_ptr, c_ptr,\n",
    "    m, n, k,\n",
    "    stride_am, stride_ak,\n",
    "    stride_bk, stride_bn,\n",
    "    stride_cm, stride_cn,\n",
    "    bm: tl.constexpr, bn: tl.constexpr, bk: tl.constexpr\n",
    "):\n",
    "    pid_m, pid_n = tl.program_id(0), tl.program_id(1)\n",
    "    rm = get_1d_offset(bm, pid_m)\n",
    "    rn = get_1d_offset(bn, pid_n)\n",
    "    # TODO: do we need rk\n",
    "    rk = get_1d_offset(k, 0)\n",
    "    offs_a = a_ptr + get_2d_offset(rm, k, stride_am, stride_ak)\n",
    "    offs_b = b_ptr + get_2d_offset(k, rn, stride_bk, stride_bn)\n",
    "\n",
    "    mask_a = get_2d_mask(rm, rk, m, k)\n",
    "    mask_b = get_2d_mask(rk, rn, k, n)\n",
    "\n",
    "    a = tl.load(offs_a, mask=mask_a)\n",
    "    b = tl.load(offs_b, mask=mask_b)\n",
    "    acc = tl.dot(a, b)\n",
    "    c = c_ptr + get_2d_offset(rm, rn, stride_cm, stride_cn)\n",
    "    mask = get_2d_mask(rm, rn, m, n)\n",
    "    tl.store(c, acc, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def matmul2(a, b, matmul_k_fn, bs=16, group_sz=None):\n",
    "    check_tensors_gpu_ready(a, b)\n",
    "    assert a.shape[1] == b.shape[0]\n",
    "    (m, k), (_, n) = a.shape, b.shape\n",
    "\n",
    "    c = torch.zeros((m, n), device=a.device, dtype=torch.float16)\n",
    "    grid = lambda meta: (triton.cdiv(m, meta[\"bm\"]), triton.cdiv(n, meta[\"bn\"]))\n",
    "    naive_matmul_k[grid](\n",
    "        a, b, c, m, n, k,\n",
    "        a.stride(0), a.stride(1),\n",
    "        b.stride(0), b.stride(1),\n",
    "        c.stride(0), c.stride(1),\n",
    "        bm=bs, bn=bs, bk=bs\n",
    "    )\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_matmul2 = partial(matmul2, matmul_k_fn=naive_matmul_k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((3, 4), dtype=torch.float32, device='cuda')\n",
    "b = torch.ones((4, 5), dtype=torch.float32, device='cuda')\n",
    "naive_matmul2(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(128)\n",
    "a = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n",
    "b = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n",
    "triton_output = naive_matmul2(a, b)\n",
    "pytorch_output = a@b\n",
    "torch.allclose(triton_output, pytorch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
