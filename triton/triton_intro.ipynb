{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.core.debugger import set_trace\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ['TRITON_INTERCEPT'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_tensors_gpu_ready(*tensors):\n",
        "    for t in tensors:\n",
        "        assert t.is_contiguous, f\"Tensor {t} is not contiguous\"\n",
        "        if not os.environ.get('TRITON_INTERCEPT') == '1':\n",
        "            assert t.is_cuda, f\"Tensor {t} is not on GPU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.tensor([1, 2, 3], device='cuda')\n",
        "check_tensors_gpu_ready(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_pid_conds(conds, pid_0=[0], pid_1=[0], pid_2=[0]):\n",
        "    # Q: Are pids 1 element lists?\n",
        "    pids = pid_0[0], pid_1[0], pid_2[0]\n",
        "    conds = conds.replace(' ', '').split(',')\n",
        "    for i, (cond, pid) in enumerate(zip(conds, pids)):\n",
        "        print(f\"{pid} ... {cond}\")\n",
        "        if cond=='': continue\n",
        "        op, threshold = cond[0], int(cond[1:])\n",
        "        if op not in ['<','>','>=','<=','=', '!=']:\n",
        "            raise ValueError(f\"Rules may only use these ops: '<','>','>=','<=','=', '!='. Invalid rule: '{condition}'.\")\n",
        "        op = '==' if op == '=' else op\n",
        "        if not eval(f'{pid} {op} {threshold}'): return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1085110356655777,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "assert test_pid_conds('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 924683176322757,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "assert test_pid_conds('>0', [1], [1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 3828887010712351,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = [1]\n",
        "b = [2, 3, 4]\n",
        "for i, j in zip(a,  b):\n",
        "    print(i, j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def breakpoint_if(conds, pid_0=[0], pid_1=[0], pid_2=[0]):\n",
        "    '''Stop kernel, if any condition of pids is fulfilled'''\n",
        "    if test_pid_conds(conds, pid_0, pid_1, pid_2): set_trace()\n",
        "\n",
        "def print_if(txt, conds, pid_0=[0], pid_1=[0], pid_2=[0]):\n",
        "    '''Print txt, if any condition of pids is fulfilled'''\n",
        "    if test_pid_conds(conds, pid_0, pid_1, pid_2): print(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cdiv(a, b): return (a + b - 1) // b\n",
        "assert cdiv(10, 2) == 5\n",
        "assert cdiv(10, 3) == 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import triton\n",
        "import triton.language as tl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def copy(x, bs, kernel_fn):\n",
        "    z = torch.zeros_like(x, device=x.device)\n",
        "    check_tensors_gpu_ready(x, z)\n",
        "    n = x.numel()\n",
        "    n_blocks = cdiv(n, bs)\n",
        "    grid = (n_blocks, )\n",
        "\n",
        "    kernel_fn[grid](x, z, n, bs)\n",
        "    return z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@triton.jit\n",
        "def copy_k(x_ptr, z_ptr, n, bs: tl.constexpr):\n",
        "    pid = tl.program_id(0)\n",
        "    offs = pid * bs + tl.arange(0, bs)\n",
        "    mask = offs < n\n",
        "    x = tl.load(x_ptr + offs, mask)\n",
        "    tl.store(z_ptr + offs, x, mask)\n",
        "    # print(\"n is {}\".format(n))\n",
        "\n",
        "    # print(f\"pid = {pid} | offs = {offs}, mask = {mask}, x = {x}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 475149065044521,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1, 2, 3, 4, 5, 6], device='cuda')\n",
        "x.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "z = copy(x, 2, copy_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 500701843006303,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "x, z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Addition using triton kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@triton.jit\n",
        "def add_kernel(x_ptr, y_ptr, output_ptr, n_elements, bs:tl.constexpr):\n",
        "    pid = tl.program_id(0)\n",
        "    offs = pid * bs + tl.arange(0, bs)\n",
        "    mask = offs < n_elements\n",
        "\n",
        "    x = tl.load(x_ptr + offs, mask)\n",
        "    y = tl.load(y_ptr + offs, mask)\n",
        "    tl.store(output_ptr + offs, x + y, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add(x: torch.tensor, y: torch.tensor, bs) -> torch.tensor:\n",
        "    output = torch.empty_like(x)\n",
        "    check_tensors_gpu_ready(x, y, output)\n",
        "    n_elements = x.numel()\n",
        "    n_blocks = cdiv(n_elements, bs)\n",
        "    grid = (n_blocks, )\n",
        "\n",
        "    add_kernel[grid](x, y, output, n_elements, bs)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 928208842059292,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "bs = 128; size = 128 * 16\n",
        "\n",
        "x = torch.rand(size, device='cuda')\n",
        "y = torch.rand(size, device='cuda')\n",
        "output_torch = x + y\n",
        "output_triton = add(x, y, bs)\n",
        "print(output_triton)\n",
        "torch.allclose(output_torch, output_triton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gpt-dev (local)",
      "language": "python",
      "name": "gpt-dev_local"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
