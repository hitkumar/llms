{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "output": {
          "id": 8016237525065038,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/htkumar/local/miniconda3/envs/gpt-2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "output": {
          "id": 480524341136371,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1548653149400425,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 987026849497644,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_bf16_supported()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.tril(torch.ones(8, 8)).view(1, 1, 8, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.arange(12).view(2, 2, 3)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q, k, v = x.chunk(3, dim=2)\n",
        "q.shape, k.shape, v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q, k, v = x.split(1, dim=2)\n",
        "q.shape, k.shape, v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "module_dict = nn.ModuleDict(\n",
        "    dict(\n",
        "        module_1=nn.Linear(10, 10),\n",
        "        module_2=nn.Linear(10, 10),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "module_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q.shape[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.arange(6).view(2, 3)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a.t().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "output": {
          "id": 843703344297053,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 4]), torch.float64)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.arange(12).view(3, 4).double()\n",
        "a.shape, a.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "output": {
          "id": 1604350213748842,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n",
              "        [0.0321, 0.0871, 0.2369, 0.6439],\n",
              "        [0.0321, 0.0871, 0.2369, 0.6439]], dtype=torch.float64)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = F.softmax(a, dim=1)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "topk_probs, topk_indices = torch.topk(a, 2, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "output": {
          "id": 521241530453171,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6439, 0.2369],\n",
              "        [0.6439, 0.2369],\n",
              "        [0.6439, 0.2369]], dtype=torch.float64)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topk_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "output": {
          "id": 2130164914023183,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3, 2],\n",
              "        [3, 2],\n",
              "        [3, 2]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topk_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "output": {
          "id": 8018642498146125,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [0],\n",
              "        [0]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = torch.multinomial(topk_probs, 1)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "output": {
          "id": 1427999184524665,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "output": {
          "id": 1944377789312867,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3],\n",
              "        [3],\n",
              "        [3]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xcol = torch.gather(topk_indices, -1, b)\n",
        "xcol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "output": {
          "id": 1205590180895716,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1],\n",
              "        [4, 3]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.tensor([[1, 2], [3, 4]])\n",
        "torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "output": {
          "id": 439701008875541,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 2]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.gather(t, 0, torch.tensor([[0, 0], [1, 0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "85155958-28a9-4f49-844f-e50516dbc8c5",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "gpt-2 (local)",
      "language": "python",
      "name": "gpt-2_local"
    }
  }
}
