{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 811826121083322,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_hf = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "sd_hf = model_hf.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "output": {
          "id": 1011489096635219,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset\n",
        "from model import GPT, GPTConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"/home/htkumar/llms/gpt2_karpathy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1111281393312275,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "model = GPT(GPTConfig(vocab_size=50304))  # power of 2 is better for the GPUs\n",
        "model.to(\"cuda:0\")\n",
        "model = torch.compile(model)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 387136553853281,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = torch.load(\"/home/htkumar/llms/gpt2_karpathy/logs/model_00000.pt\")\n",
        "a.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1242253306939004,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a[\"model\"].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1012033847144086,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(a[\"model\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1415154429166371,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a[0:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1334712374109700,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 358193103975925,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_bf16_supported()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 460782253564857,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.tril(torch.ones(8, 8)).view(1, 1, 8, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1749601785445025,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "x = torch.arange(12).view(2, 2, 3)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1884320715324407,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "q, k, v = x.chunk(3, dim=2)\n",
        "q.shape, k.shape, v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 455146967454013,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "q, k, v = x.split(1, dim=2)\n",
        "q.shape, k.shape, v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "module_dict = nn.ModuleDict(\n",
        "    dict(\n",
        "        module_1=nn.Linear(10, 10),\n",
        "        module_2=nn.Linear(10, 10),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 3892652207619737,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "module_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 490528413533711,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "q.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1162430931665391,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "q.shape[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 3483441518619692,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = torch.arange(6).view(2, 3)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1501707360740072,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a.t().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 457653246986947,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = torch.arange(12).view(3, 4).double()\n",
        "a.shape, a.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 437219712540773,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = F.softmax(a, dim=1)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topk_probs, topk_indices = torch.topk(a, 2, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1586628228785650,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "topk_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1136044267482862,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "topk_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 7727262957362172,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "b = torch.multinomial(topk_probs, 1)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 989682702862967,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 3865948780358782,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "xcol = torch.gather(topk_indices, -1, b)\n",
        "xcol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 441781708807519,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "t = torch.tensor([[1, 2], [3, 4]])\n",
        "torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 437536875794784,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.gather(t, 0, torch.tensor([[0, 0], [1, 0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1414781922574115,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = torch.tensor(1)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 7649666835129514,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 454530247200409,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "len(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 485231607398396,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "t0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t1 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1422872198389354,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "(t1 - t0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time.time??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_lr = 6e-4\n",
        "min_lr = max_lr * 0.1\n",
        "warmup_steps = 10\n",
        "max_steps = 50\n",
        "\n",
        "\n",
        "def get_lr(it):\n",
        "    # linear warmup\n",
        "    if it < warmup_steps:\n",
        "        return max_lr * (it + 1) / warmup_steps\n",
        "    elif it > max_steps:\n",
        "        return min_lr\n",
        "    # cosine decay\n",
        "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
        "    return min_lr + coeff * (max_lr - min_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 8059968670720695,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "iters = list(range(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 483191510920635,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "lrs = [get_lr(it) for it in iters]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 2111884599182869,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use(\"_mpl-gallery\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 778608654263023,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(iters, lrs, linewidth=2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 7495874297201745,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1257448388954268,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "from train_gpt2 import GPT, GPTConfig\n",
        "\n",
        "model = GPT(GPTConfig(vocab_size=50304))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = model.configure_optimizers(\n",
        "    weight_decay=0.1, learning_rate=3e-4, device=\"cuda\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer.param_groups[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(optimizer.param_groups[1][\"params\"])\n",
        "# same as number of parameters in this group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer.param_groups[0][\"lr\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inspect.signature(torch.optim.AdamW).parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_dict = {pn: p for pn, p in model.named_parameters()}\n",
        "params_dict[\"transformer.wte.weight\"].requires_grad\n",
        "len(params_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_dict = {pn: p for pn, p in params_dict.items() if p.requires_grad}\n",
        "len(params_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "decay_params = [p for n, p in params_dict.items() if p.dim() >= 2]\n",
        "nondecay_params = [p for n, p in params_dict.items() if p.dim() < 2]\n",
        "len(decay_params), len(nondecay_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_decay_params = sum(p.numel() for p in decay_params)\n",
        "num_nondecay_params = sum(p.numel() for p in nondecay_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(num_decay_params, num_nondecay_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fineweb edu dataset processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 795068326169758,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "import multiprocessing as mp\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remote_name = \"sample-10BT\"  # these are 10B gpt2 tokens sampled from the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1452340485406551,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "# fw = load_dataset(\"HuggingFaceFW/fineweb-edu\", name=remote_name, split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1876141322855230,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "max_value = np.iinfo(np.uint16).max\n",
        "max_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 2175549716138271,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "np.iinfo(np.uint16).min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 476743288234557,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = np.array([2**16 - 1])\n",
        "a.astype(np.uint16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1035975357858227,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "os.path.join(os.path.dirname(__file__), \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 3808513809474620,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "os.cpu_count() // 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 991882295496775,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "loss = torch.tensor(3.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 847128683942014,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "loss.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "85155958-28a9-4f49-844f-e50516dbc8c5",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
