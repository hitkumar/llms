{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "output": {
          "id": 811826121083322,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/htkumar/local/miniconda3/envs/gpt-2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "output": {
          "id": 480524341136371,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "output": {
          "id": 1334712374109700,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "output": {
          "id": 358193103975925,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_bf16_supported()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 460782253564857,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.tril(torch.ones(8, 8)).view(1, 1, 8, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1749601785445025,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "x = torch.arange(12).view(2, 2, 3)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1884320715324407,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "q, k, v = x.chunk(3, dim=2)\n",
        "q.shape, k.shape, v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 455146967454013,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "q, k, v = x.split(1, dim=2)\n",
        "q.shape, k.shape, v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "module_dict = nn.ModuleDict(\n",
        "    dict(\n",
        "        module_1=nn.Linear(10, 10),\n",
        "        module_2=nn.Linear(10, 10),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 3892652207619737,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "module_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 490528413533711,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "q.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1162430931665391,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "q.shape[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 3483441518619692,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = torch.arange(6).view(2, 3)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1501707360740072,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a.t().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 457653246986947,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = torch.arange(12).view(3, 4).double()\n",
        "a.shape, a.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 437219712540773,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = F.softmax(a, dim=1)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topk_probs, topk_indices = torch.topk(a, 2, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1586628228785650,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "topk_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1136044267482862,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "topk_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 7727262957362172,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "b = torch.multinomial(topk_probs, 1)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 989682702862967,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 3865948780358782,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "xcol = torch.gather(topk_indices, -1, b)\n",
        "xcol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 441781708807519,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "t = torch.tensor([[1, 2], [3, 4]])\n",
        "torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 437536875794784,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.gather(t, 0, torch.tensor([[0, 0], [1, 0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1414781922574115,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = torch.tensor(1)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 7649666835129514,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 454530247200409,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "len(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 485231607398396,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "t0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t1 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 1422872198389354,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "(t1 - t0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time.time??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_lr = 6e-4\n",
        "min_lr = max_lr * 0.1\n",
        "warmup_steps = 10\n",
        "max_steps = 50\n",
        "\n",
        "\n",
        "def get_lr(it):\n",
        "    # linear warmup\n",
        "    if it < warmup_steps:\n",
        "        return max_lr * (it + 1) / warmup_steps\n",
        "    elif it > max_steps:\n",
        "        return min_lr\n",
        "    # cosine decay\n",
        "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
        "    return min_lr + coeff * (max_lr - min_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "output": {
          "id": 8059968670720695,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "iters = list(range(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "output": {
          "id": 483191510920635,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "lrs = [get_lr(it) for it in iters]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "output": {
          "id": 2111884599182869,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Bad key keymap.all_axes in file /mnt/xarfuse/uid-285367/b89978fe-seed-nspid4026531836_cgpid14017160-ns-4026531840/bento/server/matplotlibrc-3.1.3, line 76 ('keymap.all_axes : a                 # enable all axes')\n",
            "You probably need to get an updated matplotlibrc file from\n",
            "https://github.com/matplotlib/matplotlib/blob/v3.8.4/lib/matplotlib/mpl-data/matplotlibrc\n",
            "or from the matplotlib source distribution\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use(\"_mpl-gallery\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "output": {
          "id": 778608654263023,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5e9598ead0>]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "findfont: Font family 'Noto Sans TC' not found.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "findfont: Font family 'Noto Sans SC' not found.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "findfont: Font family 'Noto Sans TC' not found.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "findfont: Font family 'Noto Sans SC' not found.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(iters, lrs, linewidth=2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "output": {
          "id": 7495874297201745,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/data/users/htkumar'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"/home/htkumar/llms/gpt2_karpathy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "output": {
          "id": 1257448388954268,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device: cuda\n",
            "loaded 338025 in dataloader, num_batches in 1 epoch is 20\n",
            "num_decay_params: 124354560, num_nondecay_params: 121344, use_fused: True\n",
            "loss at iter 0: 10.947336196899414, time_taken: 26886.01, tokens_per_sec: 609.39, norm: 28.5688| lr: 6.0000e-05\n",
            "loss at iter 1: 9.502386093139648, time_taken: 102.37, tokens_per_sec: 160040.52, norm: 10.6576| lr: 1.2000e-04\n",
            "loss at iter 2: 9.251543998718262, time_taken: 102.20, tokens_per_sec: 160308.57, norm: 7.3724| lr: 1.8000e-04\n",
            "loss at iter 3: 9.762334823608398, time_taken: 102.43, tokens_per_sec: 159947.76, norm: 6.6542| lr: 2.4000e-04\n",
            "loss at iter 4: 9.105025291442871, time_taken: 102.46, tokens_per_sec: 159908.68, norm: 4.2449| lr: 3.0000e-04\n",
            "loss at iter 5: 8.795068740844727, time_taken: 102.47, tokens_per_sec: 159886.73, norm: 3.2619| lr: 3.6000e-04\n",
            "loss at iter 6: 8.586079597473145, time_taken: 102.64, tokens_per_sec: 159620.08, norm: 2.3602| lr: 4.2000e-04\n",
            "loss at iter 7: 8.265682220458984, time_taken: 102.58, tokens_per_sec: 159721.36, norm: 2.0503| lr: 4.8000e-04\n",
            "loss at iter 8: 7.888558387756348, time_taken: 102.35, tokens_per_sec: 160078.91, norm: 2.2141| lr: 5.4000e-04\n",
            "loss at iter 9: 7.519984245300293, time_taken: 102.92, tokens_per_sec: 159191.15, norm: 2.1464| lr: 6.0000e-04\n",
            "loss at iter 10: 7.146845817565918, time_taken: 102.67, tokens_per_sec: 159584.86, norm: 1.8100| lr: 6.0000e-04\n",
            "loss at iter 11: 6.893649101257324, time_taken: 103.20, tokens_per_sec: 158766.36, norm: 1.2600| lr: 5.9917e-04\n",
            "loss at iter 12: 6.612743377685547, time_taken: 102.65, tokens_per_sec: 159615.63, norm: 1.0859| lr: 5.9668e-04\n",
            "loss at iter 13: 6.652754306793213, time_taken: 102.59, tokens_per_sec: 159700.57, norm: 1.1984| lr: 5.9254e-04\n",
            "loss at iter 14: 6.673104286193848, time_taken: 102.27, tokens_per_sec: 160211.03, norm: 1.1515| lr: 5.8679e-04\n",
            "loss at iter 15: 6.5139031410217285, time_taken: 102.53, tokens_per_sec: 159793.04, norm: 1.4057| lr: 5.7945e-04\n",
            "loss at iter 16: 6.529476165771484, time_taken: 102.14, tokens_per_sec: 160411.86, norm: 1.2042| lr: 5.7057e-04\n",
            "loss at iter 17: 6.52205753326416, time_taken: 102.64, tokens_per_sec: 159629.72, norm: 0.8597| lr: 5.6021e-04\n",
            "loss at iter 18: 6.554071426391602, time_taken: 102.38, tokens_per_sec: 160038.28, norm: 1.2068| lr: 5.4843e-04\n",
            "loss at iter 19: 6.374093532562256, time_taken: 102.82, tokens_per_sec: 159348.40, norm: 1.6194| lr: 5.3531e-04\n",
            "loss at iter 20: 6.5022664070129395, time_taken: 102.88, tokens_per_sec: 159248.33, norm: 1.5193| lr: 5.2092e-04\n",
            "loss at iter 21: 6.1952972412109375, time_taken: 103.73, tokens_per_sec: 157954.02, norm: 1.2601| lr: 5.0535e-04\n",
            "loss at iter 22: 6.269636631011963, time_taken: 103.19, tokens_per_sec: 158781.40, norm: 1.2113| lr: 4.8870e-04\n",
            "loss at iter 23: 6.171233177185059, time_taken: 103.00, tokens_per_sec: 159064.76, norm: 1.2591| lr: 4.7107e-04\n",
            "loss at iter 24: 6.084338188171387, time_taken: 102.89, tokens_per_sec: 159239.11, norm: 1.1690| lr: 4.5258e-04\n",
            "loss at iter 25: 6.303879737854004, time_taken: 103.00, tokens_per_sec: 159064.76, norm: 0.9371| lr: 4.3332e-04\n",
            "loss at iter 26: 6.391762733459473, time_taken: 102.69, tokens_per_sec: 159546.33, norm: 1.2696| lr: 4.1343e-04\n",
            "loss at iter 27: 6.252917766571045, time_taken: 102.73, tokens_per_sec: 159479.68, norm: 1.2179| lr: 3.9303e-04\n",
            "loss at iter 28: 6.161186695098877, time_taken: 102.73, tokens_per_sec: 159490.42, norm: 0.7757| lr: 3.7224e-04\n",
            "loss at iter 29: 6.059823036193848, time_taken: 102.84, tokens_per_sec: 159318.85, norm: 0.8977| lr: 3.5118e-04\n",
            "loss at iter 30: 6.041410446166992, time_taken: 102.84, tokens_per_sec: 159308.51, norm: 0.8696| lr: 3.3000e-04\n",
            "loss at iter 31: 6.029784679412842, time_taken: 102.77, tokens_per_sec: 159429.36, norm: 0.8318| lr: 3.0882e-04\n",
            "loss at iter 32: 5.9617018699646, time_taken: 102.98, tokens_per_sec: 159102.33, norm: 0.8070| lr: 2.8776e-04\n",
            "loss at iter 33: 6.1016998291015625, time_taken: 103.96, tokens_per_sec: 157600.10, norm: 0.7647| lr: 2.6697e-04\n",
            "loss at iter 34: 6.229904651641846, time_taken: 103.46, tokens_per_sec: 158364.99, norm: 0.8166| lr: 2.4657e-04\n",
            "loss at iter 35: 6.0850067138671875, time_taken: 103.08, tokens_per_sec: 158949.60, norm: 0.7968| lr: 2.2668e-04\n",
            "loss at iter 36: 6.042623519897461, time_taken: 102.64, tokens_per_sec: 159621.93, norm: 0.9321| lr: 2.0742e-04\n",
            "loss at iter 37: 6.042093276977539, time_taken: 102.46, tokens_per_sec: 159903.10, norm: 0.7508| lr: 1.8893e-04\n",
            "loss at iter 38: 6.062716960906982, time_taken: 103.31, tokens_per_sec: 158589.75, norm: 0.9018| lr: 1.7130e-04\n",
            "loss at iter 39: 5.919795989990234, time_taken: 102.72, tokens_per_sec: 159500.04, norm: 0.9226| lr: 1.5465e-04\n",
            "loss at iter 40: 6.1255784034729, time_taken: 102.76, tokens_per_sec: 159436.39, norm: 0.8092| lr: 1.3908e-04\n",
            "loss at iter 41: 5.8815412521362305, time_taken: 103.25, tokens_per_sec: 158680.20, norm: 1.1430| lr: 1.2469e-04\n",
            "loss at iter 42: 6.003665924072266, time_taken: 103.14, tokens_per_sec: 158853.70, norm: 0.8043| lr: 1.1157e-04\n",
            "loss at iter 43: 5.858842849731445, time_taken: 103.65, tokens_per_sec: 158064.83, norm: 0.8188| lr: 9.9787e-05\n",
            "loss at iter 44: 5.805362224578857, time_taken: 103.67, tokens_per_sec: 158036.84, norm: 0.7537| lr: 8.9428e-05\n",
            "loss at iter 45: 6.007417678833008, time_taken: 103.42, tokens_per_sec: 158429.24, norm: 0.8256| lr: 8.0553e-05\n",
            "loss at iter 46: 6.145845413208008, time_taken: 103.04, tokens_per_sec: 159005.87, norm: 0.7440| lr: 7.3215e-05\n",
            "loss at iter 47: 6.028573513031006, time_taken: 103.23, tokens_per_sec: 158715.39, norm: 0.7564| lr: 6.7460e-05\n",
            "loss at iter 48: 5.962883949279785, time_taken: 102.70, tokens_per_sec: 159534.11, norm: 0.6318| lr: 6.3324e-05\n",
            "loss at iter 49: 5.874952793121338, time_taken: 102.68, tokens_per_sec: 159567.82, norm: 0.7045| lr: 6.0832e-05\n",
            "loss at iter 50: 5.887086868286133, time_taken: 102.82, tokens_per_sec: 159345.45, norm: 0.5462| lr: 6.0000e-05\n",
            "loss at iter 51: 5.922815322875977, time_taken: 103.03, tokens_per_sec: 159019.49, norm: 0.6640| lr: 6.0000e-05\n",
            "loss at iter 52: 5.871680736541748, time_taken: 103.35, tokens_per_sec: 158531.95, norm: 0.6512| lr: 6.0000e-05\n",
            "loss at iter 53: 5.998493194580078, time_taken: 103.95, tokens_per_sec: 157610.59, norm: 0.7931| lr: 6.0000e-05\n",
            "loss at iter 54: 6.126043319702148, time_taken: 103.76, tokens_per_sec: 157902.48, norm: 0.8497| lr: 6.0000e-05\n"
          ]
        }
      ],
      "source": [
        "from train_gpt2 import GPT, GPTConfig\n",
        "\n",
        "model = GPT(GPTConfig(vocab_size=50304))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_decay_params: 124354560, num_nondecay_params: 121344, use_fused: True\n"
          ]
        }
      ],
      "source": [
        "optimizer = model.configure_optimizers(\n",
        "    weight_decay=0.1, learning_rate=3e-4, device=\"cuda\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['params', 'weight_decay', 'lr', 'betas', 'eps', 'amsgrad', 'foreach', 'maximize', 'capturable', 'differentiable', 'fused'])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimizer.param_groups[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(optimizer.param_groups[1][\"params\"])\n",
        "# same as number of parameters in this group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0003"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimizer.param_groups[0][\"lr\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mappingproxy({'params': <Parameter \"params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]]\">,\n",
              "              'lr': <Parameter \"lr: Union[float, torch.Tensor] = 0.001\">,\n",
              "              'betas': <Parameter \"betas: Tuple[float, float] = (0.9, 0.999)\">,\n",
              "              'eps': <Parameter \"eps: float = 1e-08\">,\n",
              "              'weight_decay': <Parameter \"weight_decay: float = 0.01\">,\n",
              "              'amsgrad': <Parameter \"amsgrad: bool = False\">,\n",
              "              'maximize': <Parameter \"maximize: bool = False\">,\n",
              "              'foreach': <Parameter \"foreach: Optional[bool] = None\">,\n",
              "              'capturable': <Parameter \"capturable: bool = False\">,\n",
              "              'differentiable': <Parameter \"differentiable: bool = False\">,\n",
              "              'fused': <Parameter \"fused: Optional[bool] = None\">})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inspect.signature(torch.optim.AdamW).parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "148"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params_dict = {pn: p for pn, p in model.named_parameters()}\n",
        "params_dict[\"transformer.wte.weight\"].requires_grad\n",
        "len(params_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "148"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params_dict = {pn: p for pn, p in params_dict.items() if p.requires_grad}\n",
        "len(params_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 98)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decay_params = [p for n, p in params_dict.items() if p.dim() >= 2]\n",
        "nondecay_params = [p for n, p in params_dict.items() if p.dim() < 2]\n",
        "len(decay_params), len(nondecay_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_decay_params = sum(p.numel() for p in decay_params)\n",
        "num_nondecay_params = sum(p.numel() for p in nondecay_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124354560 121344\n"
          ]
        }
      ],
      "source": [
        "print(num_decay_params, num_nondecay_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fineweb edu dataset processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "output": {
          "id": 795068326169758,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/htkumar/local/miniconda3/envs/gpt-2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing as mp\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "remote_name = \"sample-10BT\"  # these are 10B gpt2 tokens sampled from the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "output": {
          "id": 1452340485406551,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "# fw = load_dataset(\"HuggingFaceFW/fineweb-edu\", name=remote_name, split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "output": {
          "id": 1876141322855230,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65535"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_value = np.iinfo(np.uint16).max\n",
        "max_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "output": {
          "id": 2175549716138271,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.iinfo(np.uint16).min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "output": {
          "id": 476743288234557,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([65535], dtype=uint16)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.array([2**16 - 1])\n",
        "a.astype(np.uint16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "output": {
          "id": 1035975357858227,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name '__file__' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n",
            "\u001b[0;32m----> 1\u001b[0m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ],
      "source": [
        "os.path.join(os.path.dirname(__file__), \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "output": {
          "id": 3808513809474620,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.cpu_count() // 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "output": {
          "id": 991882295496775,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "loss = torch.tensor(3.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "output": {
          "id": 847128683942014,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.1000)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "85155958-28a9-4f49-844f-e50516dbc8c5",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "gpt-2 (local)",
      "language": "python",
      "name": "gpt-2_local"
    }
  }
}
