{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from importlib.metadata import version\n",
        "from dpo_utils import *\n",
        "\n",
        "pkgs = [\n",
        "    \"tiktoken\",\n",
        "    \"torch\",\n",
        "]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "enc = tiktoken.get_encoding('gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "file_path = \"/home/htkumar/llms/rasbt_llms_from_scratch/instruction-data-with-preference.json\"\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pp(data[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pprint.pp(data[999])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pprint.pp(data[900])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that approximately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_input = format_input(data[50])\n",
        "print(model_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "desired_response = f\"### Response: \\n{data[50]['chosen']}\"\n",
        "print(desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "possible_response = f\"### Response: \\n{data[50]['rejected']}\"\n",
        "print(possible_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response_format = lambda entry: f\"### Response: \\n{entry['chosen']}\"\n",
        "print(response_format(data[50]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_portion = int(len(data) * 0.85)\n",
        "test_portion = int(len(data) * 0.1)\n",
        "val_portion = len(data) - train_portion - test_portion\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion: train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(train_data), len(test_data), len(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.ones([10]); b = torch.zeros([10])\n",
        "c = [a, b]\n",
        "d = torch.stack(c); d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "print(device)\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    mask_prompt_tokens=True,\n",
        "    allowed_max_length=1024,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_data = data[:2]\n",
        "for i in example_data:\n",
        "    pprint.pp(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from torch.utils.data import DataLoader\n",
        "tokenizer = tiktoken.get_encoding('gpt2')\n",
        "\n",
        "example_dataset = PreferenceDataset(example_data, tokenizer)\n",
        "example_dataloader = DataLoader(\n",
        "    example_dataset,\n",
        "    batch_size=2,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch = next(iter(example_dataloader))\n",
        "batch.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch['prompt'][0].shape, batch['prompt'][1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch['chosen'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch['rejected']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decode_tokens_from_batch(token_ids, tokenizer):\n",
        "    ids = token_ids.flatten().tolist()\n",
        "    return tokenizer.decode(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = decode_tokens_from_batch(\n",
        "    token_ids=batch['prompt'][0],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = decode_tokens_from_batch(\n",
        "    token_ids=batch['rejected'][0],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch['prompt'][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch['chosen_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = decode_tokens_from_batch(\n",
        "    token_ids=batch['rejected'][0][batch['rejected_mask'][0]],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = decode_tokens_from_batch(\n",
        "    token_ids=batch['chosen'][0][batch['chosen_mask'][0]],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### mask is used to ignore prompt and padding tokens while computing DPO loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_dataset = PreferenceDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_dataset = PreferenceDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = PreferenceDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch in train_loader:\n",
        "    print(batch['chosen'].shape, batch['rejected'].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load instruction finetuned model\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "finetuned_model_path = Path('/home/htkumar/llms/rasbt_llms_from_scratch/gpt2-medium-sft.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gpt_model import GPTModel, generate, text_to_token_ids, token_ids_to_text\n",
        "from gpt_download import load_gpt2, BASE_CONFIG, model_configs\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "model = GPTModel(BASE_CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_state_dict(\n",
        "    torch.load(\n",
        "        '/home/htkumar/llms/rasbt_llms_from_scratch/gpt2-medium-sft.pth',\n",
        "        map_location=device,\n",
        "        weights_only=True\n",
        "    )\n",
        ")\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input = format_input(data[2])\n",
        "print(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG['context_length'],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "policy_model = model\n",
        "reference_model = GPTModel(BASE_CONFIG)\n",
        "reference_model.load_state_dict(\n",
        "    torch.load(\n",
        "        '/home/htkumar/llms/rasbt_llms_from_scratch/gpt2-medium-sft.pth',\n",
        "        map_location=device,\n",
        "        weights_only=True\n",
        "    )\n",
        ")\n",
        "reference_model.eval();\n",
        "policy_model.to(device)\n",
        "reference_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### DPO loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.tensor([1., 2., 3.])\n",
        "torch.log(F.softmax(a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "F.log_softmax(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample data\n",
        "logits = torch.tensor(\n",
        "    [[2.0, 1.0, 0.1],\n",
        "    [0.5, 2.5, 0.3]]\n",
        ")\n",
        "targets = torch.tensor([0, 2])\n",
        "logits.shape, targets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_softmax_logits = F.log_softmax(logits, dim=1)\n",
        "selected_log_probs = torch.gather(\n",
        "    input=log_softmax_logits,\n",
        "    dim=1,\n",
        "    index=targets.unsqueeze(1)\n",
        ").squeeze(1)\n",
        "print(log_softmax_logits)\n",
        "print(selected_log_probs)\n",
        "print(selected_log_probs.shape)\n",
        "manual_loss = -selected_log_probs.mean()\n",
        "print(manual_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_entropy_loss = F.cross_entropy(logits, targets)\n",
        "print(cross_entropy_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t = torch.tensor(\n",
        "  [[1., 2.,],\n",
        "   [3., 4.]]\n",
        ")\n",
        "m = torch.tensor(\n",
        "    [[1, 1, 1],\n",
        "    [0, 1, 1]]\n",
        ")\n",
        "\n",
        "selected_nums = torch.gather(\n",
        "    input=t,\n",
        "    dim=1,\n",
        "    index=m\n",
        ")\n",
        "selected_nums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_probs = torch.tensor([\n",
        "    [0.5, 0.3, 0.2],\n",
        "    [1.0, 2.0, 3.0]\n",
        "])\n",
        "print(log_probs.mean(-1, keepdim=True))\n",
        "mask = torch.tensor([\n",
        "    [False, True, True],\n",
        "    [False, True, True]\n",
        "])\n",
        "log_probs = log_probs * mask\n",
        "(log_probs.sum(-1) / mask.sum(-1)).shape\n",
        "log_probs.mean(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cross entropy is the minus of mean of log_probs of the correct label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "next(iter(train_loader)).keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_batch = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compute_dpo_loss_batch(test_batch, policy_model, reference_model, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "res = evaluate_dpo_loss_loader(\n",
        "    policy_model=policy_model,\n",
        "    reference_model=reference_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    beta=0.1,\n",
        "    eval_iter=5\n",
        ")\n",
        "\n",
        "print('Training loss: ', res['train_loss'])\n",
        "print('val loss: ', res['val_loss'])\n",
        "(res['train_chosen_reward'] - res['train_rejected_reward']), (res['val_chosen_reward'] - res['val_rejected_reward'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in val_data[5:7]:\n",
        "    input_text = format_input(data)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=policy_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG['context_length'],\n",
        "        eos_id=50256,\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {data['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text}\")\n",
        "    print(\"\\n----------------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "optimizer = torch.optim.AdamW(policy_model.parameters(), lr=5e-6, weight_decay=0.01)\n",
        "num_epochs = 1\n",
        "tracking = train_model_dpo_simple(\n",
        "    policy_model=policy_model,\n",
        "    reference_model=reference_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=num_epochs,\n",
        "    beta=0.1,\n",
        "    eval_freq=5,\n",
        "    eval_iter=5,\n",
        "    start_context=val_data[2],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_mins = (end_time - start_time)/60\n",
        "print(f\"{execution_time_mins:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(tracking['train_losses'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gpt_model import plot_losses\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(tracking['train_losses']))\n",
        "plot_losses(\n",
        "    epochs_seen=epochs_tensor,\n",
        "    tokens_seen=tracking['tokens_seen'],\n",
        "    train_losses=tracking['train_losses'],\n",
        "    val_losses=tracking['val_losses'],\n",
        "    label='loss'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_rewards_margins = [i-j for i, j in zip(tracking['train_chosen_rewards'], tracking['train_rejected_rewards'])]\n",
        "val_reward_margins = [i-j for i, j in zip(tracking['val_chosen_rewards'], tracking['val_rejected_rewards'])]\n",
        "\n",
        "plot_losses(\n",
        "    epochs_seen=epochs_tensor,\n",
        "    tokens_seen=tracking['tokens_seen'],\n",
        "    train_losses=train_rewards_margins,\n",
        "    val_losses=val_reward_margins,\n",
        "    label='loss'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in val_data[:10]:\n",
        "    input_text = format_input(data)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=reference_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG['context_length'],\n",
        "        eos_id=50256,\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    ref_response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=policy_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG['context_length'],\n",
        "        eos_id=50256,\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    policy_response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {data['output']}\")\n",
        "    print(f\"\\nReference Model response:\\n>> {ref_response_text}\")\n",
        "    print(f\"\\nPolicy Model response:\\n>> {policy_response_text}\")\n",
        "    print(\"\\n----------------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in test_data[:5]:\n",
        "    input_text = format_input(data)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=reference_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG['context_length'],\n",
        "        eos_id=50256,\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    ref_response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=policy_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG['context_length'],\n",
        "        eos_id=50256,\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    policy_response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {data['output']}\")\n",
        "    print(f\"\\nReference Model response:\\n>> {ref_response_text}\")\n",
        "    print(f\"\\nPolicy Model response:\\n>> {policy_response_text}\")\n",
        "    print(\"\\n----------------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the model after DPO\n",
        "torch.save(policy_model.state_dict(), '/home/htkumar/llms/rasbt_llms_from_scratch/gpt2-medium-dpo.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dpo_model = GPTModel(BASE_CONFIG)\n",
        "dpo_model.load_state_dict(\n",
        "    torch.load(\n",
        "        '/home/htkumar/llms/rasbt_llms_from_scratch/gpt2-medium-dpo.pth',\n",
        "        map_location=device,\n",
        "        weights_only=True\n",
        "    )\n",
        ")\n",
        "dpo_model.to(device)\n",
        "dpo_model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in test_data[:5]:\n",
        "    input_text = format_input(data)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=reference_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG['context_length'],\n",
        "        eos_id=50256,\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    ref_response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=dpo_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG['context_length'],\n",
        "        eos_id=50256,\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    policy_response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {data['output']}\")\n",
        "    print(f\"\\nReference Model response:\\n>> {ref_response_text}\")\n",
        "    print(f\"\\nPolicy Model response:\\n>> {policy_response_text}\")\n",
        "    print(\"\\n----------------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "fedaaae2-7fcd-436b-91e3-5ad41d916e50",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "gpt-dev (local)",
      "language": "python",
      "name": "gpt-dev_local"
    },
    "language_info": {
      "name": "plaintext"
    }
  }
}
