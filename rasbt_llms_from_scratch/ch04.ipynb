{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.set_printoptions(sci_mode=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 575804358203276,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "batch_example = torch.randn(2, 5)\n",
        "layers = nn.Sequential(\n",
        "    nn.Linear(5, 6),\n",
        "    nn.ReLU()\n",
        ")\n",
        "out = layers(batch_example)\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 834403115572373,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "mean = out.mean(dim=-1, keepdim=True)\n",
        "var = out.var(dim=-1, keepdim=True)\n",
        "print(f\"mean={mean}\")\n",
        "print(f\"var={var}\")\n",
        "var.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 877525544447443,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "out_norm = (out - mean) / torch.sqrt(var)\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "print(f\"mean={mean}\")\n",
        "print(f\"var={var}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is (B, T, emb_dim)\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        # should be correction=0 in PT 2.0\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * x_norm + self.shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 2006181809829935,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "ln = LayerNorm(emb_dim=5)\n",
        "out = ln(batch_example)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output": {
          "id": 867806575566742,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "print(f\"mean={mean}\")\n",
        "print(f\"var={var}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.linspace(-1, 1, 10); a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "y_gelu, y_relu = gelu(x), relu(x)\n",
        "plt.figure(figsize=(8, 3))\n",
        "\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], ['GELU', 'RELU']), 1):\n",
        "    plt.subplot(1, 2, i)\n",
        "    plt.plot(x, y)\n",
        "    plt.title(f\"{label} activation\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(f\"{label}(x)\")\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for p in layers.parameters():\n",
        "    print(p.numel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "58369cf4-f6dc-44cd-93dc-737432719969",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "gpt-dev (local)",
      "language": "python",
      "name": "gpt-dev_local"
    },
    "language_info": {
      "name": "plaintext"
    }
  }
}
