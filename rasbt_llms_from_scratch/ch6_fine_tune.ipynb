{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.7.2\n",
      "numpy version: 1.24.3\n",
      "tiktoken version: 0.6.0\n",
      "torch version: 2.1.2\n",
      "tensorflow version: 2.13.0\n",
      "pandas version: 2.0.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "    \"tensorflow\",\n",
    "    \"pandas\"\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('sms_spam_collection/SMSSpamCollection.tsv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "data_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists, no need to download\")\n",
    "        return\n",
    "    \n",
    "    # download the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "    \n",
    "    # unzip the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "    \n",
    "    # add .tsv extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists, no need to download\n"
     ]
    }
   ],
   "source": [
    "download_and_unzip(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=[\"label\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n",
    "# unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label == 'spam'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df.label == 'spam'].shape[0]\n",
    "    ham_subset = df[df.label == 'ham'].sample(num_spam, random_state=123)\n",
    "    balanced_df = pd.concat([ham_subset, df[df.label == 'spam']])\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     747\n",
       "spam    747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df['label'] = balanced_df['label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>747 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "5         1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "8         1  WINNER!! As a valued network customer you have...\n",
       "9         1  Had your mobile 11 months or more? U R entitle...\n",
       "11        1  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[747 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[balanced_df.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3568</td>\n",
       "      <td>1</td>\n",
       "      <td>Collect your VALENTINE'S weekend to PARIS inc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537</td>\n",
       "      <td>0</td>\n",
       "      <td>How's it feel? Mr. Your not my real Valentine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4531</td>\n",
       "      <td>0</td>\n",
       "      <td>Don't forget though that I love you .... And I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3102</td>\n",
       "      <td>0</td>\n",
       "      <td>Pathaya enketa maraikara pa'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>3437</td>\n",
       "      <td>0</td>\n",
       "      <td>If india win or level series means this is rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>2525</td>\n",
       "      <td>1</td>\n",
       "      <td>FREE entry into our £250 weekly comp just send...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>2409</td>\n",
       "      <td>0</td>\n",
       "      <td>Dear where you will be when i reach there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>2521</td>\n",
       "      <td>0</td>\n",
       "      <td>Misplaced your number and was sending texts to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>4589</td>\n",
       "      <td>0</td>\n",
       "      <td>I wanted to wish you a Happy New Year and I wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  label                                               text\n",
       "0      3568      1  Collect your VALENTINE'S weekend to PARIS inc ...\n",
       "1      1537      0  How's it feel? Mr. Your not my real Valentine ...\n",
       "2      4531      0  Don't forget though that I love you .... And I...\n",
       "3         8      1  WINNER!! As a valued network customer you have...\n",
       "4      3102      0                       Pathaya enketa maraikara pa'\n",
       "...     ...    ...                                                ...\n",
       "1489   3437      0  If india win or level series means this is rec...\n",
       "1490   2525      1  FREE entry into our £250 weekly comp just send...\n",
       "1491   2409      0          Dear where you will be when i reach there\n",
       "1492   2521      0  Misplaced your number and was sending texts to...\n",
       "1493   4589      0  I wanted to wish you a Happy New Year and I wa...\n",
       "\n",
       "[1494 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.sample(frac=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'text'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # shuffle dataframe\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    \n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    train_df = df[:train_end]\n",
    "    valid_df = df[train_end: validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1045, 2), (149, 2), (300, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.shape, validation_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.csv', index=None)\n",
    "validation_df.to_csv('validation.csv', index=None)\n",
    "test_df.to_csv('test.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50256]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2437, 389, 345, 1804]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"How are you doing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.encode??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256) -> None:\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # pre-tokenizer texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data['text']\n",
    "        ]\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # truncate texts if they are longer than max length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        \n",
    "        # Add padding\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        encoded_text = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index]['label']\n",
    "        return (\n",
    "            torch.tensor(encoded_text, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            if len(encoded_text) > max_length:\n",
    "                max_length = len(encoded_text)\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Age': [25, 30, 35, 40],\n",
    "        'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.iloc[0]['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file='train.csv',\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = SpamDataset(\n",
    "    csv_file='validation.csv',\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file='test.csv',\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.max_length, test_dataset.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 120]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for text, label in test_loader:\n",
    "    print(text.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 19, 38)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://openaipublic.blob.core.windows.net/gpt-2/models/124M/checkpoint',\n",
       " 'downloaded_models/checkpoint')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "filename = 'checkpoint'\n",
    "model_dir = 'downloaded_models'\n",
    "model_size = '124M'\n",
    "\n",
    "file_url = os.path.join(base_url, model_size, filename)\n",
    "file_path = os.path.join(model_dir, filename)\n",
    "file_url, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content-Length': '77', 'Content-Type': 'application/octet-stream', 'Content-MD5': 'ygNo/NPEwamaykJRHQwfEg==', 'Last-Modified': 'Wed, 02 Dec 2020 17:33:04 GMT', 'ETag': '0x8D896E85318642F', 'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0', 'x-ms-request-id': 'b9b36587-e01e-0009-68bb-aa4c5c000000', 'x-ms-version': '2009-09-19', 'x-ms-meta-Mtime': '2019-09-17T04:52:11.325000000Z', 'x-ms-lease-status': 'unlocked', 'x-ms-blob-type': 'BlockBlob', 'Date': 'Mon, 20 May 2024 13:41:24 GMT'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(file_url, stream=True)\n",
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sms+spam+collection.zip: 100%|██████████| 77.0/77.0 [00:00<00:00, 93.8kiB/s]\n"
     ]
    }
   ],
   "source": [
    "file_size = int(response.headers.get(\"content-length\", 0))\n",
    "block_size = 1024\n",
    "progress_bar_description = url.split(\"/\")[-1]\n",
    "with tqdm(total=file_size, unit='iB', unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        for chunk in response.iter_content(block_size):\n",
    "            progress_bar.update(len(chunk))\n",
    "            file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Couldn't match files for checkpoint downloaded_models/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "tk_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "tk_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(file_path, destination):\n",
    "    response = requests.get(file_path, stream=True)\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File exists: {destination}\")\n",
    "            return\n",
    "\n",
    "    block_size = 1024\n",
    "    progress_bar_description = file_path.split(\"/\")[-1]\n",
    "    with tqdm(total=file_size, unit='iB', unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        with open(destination, \"wb\") as file:\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))\n",
    "                file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # model sizes available in https://github.com/openai/gpt-2/blob/master/DEVELOPERS.md\n",
    "    allowed_sizes = ('124M', '355M', '774M', '1558M')\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size {model_size} not in {allowed_sizes}\")\n",
    "    \n",
    "    # define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        'checkpoint','encoder.json','hparams.json',\n",
    "        'model.ckpt.data-00000-of-00001', 'model.ckpt.index',\n",
    "        'model.ckpt.meta', 'vocab.bpe'\n",
    "    ]\n",
    "\n",
    "    # download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        print(file_url, file_path)\n",
    "        download_file(file_url, file_path)\n",
    "    \n",
    "    # Add tf loading part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/checkpoint gpt2/124M/checkpoint\n",
      "File exists: gpt2/124M/checkpoint\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/encoder.json gpt2/124M/encoder.json\n",
      "File exists: gpt2/124M/encoder.json\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/hparams.json gpt2/124M/hparams.json\n",
      "File exists: gpt2/124M/hparams.json\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.data-00000-of-00001 gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File exists: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.index gpt2/124M/model.ckpt.index\n",
      "File exists: gpt2/124M/model.ckpt.index\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.meta gpt2/124M/model.ckpt.meta\n",
      "File exists: gpt2/124M/model.ckpt.meta\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/vocab.bpe gpt2/124M/vocab.bpe\n",
      "File exists: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "download_and_load_gpt2(model_size='124M', models_dir='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join('gpt2', '124M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt2/124M/model.ckpt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "tf_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = json.load(open(os.path.join(model_dir, 'hparams.json')))\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = tf.train.list_variables(tf_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, _ = variables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/h0/attn/c_attn/w'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768, 2304)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.load_variable(tf_ckpt_path, name).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 768)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['wpe'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attn', 'ln_1', 'ln_2', 'mlp'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['blocks'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.train.latest_checkpoint??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/checkpoint gpt2/124M/checkpoint\n",
      "File exists: gpt2/124M/checkpoint\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/encoder.json gpt2/124M/encoder.json\n",
      "File exists: gpt2/124M/encoder.json\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/hparams.json gpt2/124M/hparams.json\n",
      "File exists: gpt2/124M/hparams.json\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.data-00000-of-00001 gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File exists: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.index gpt2/124M/model.ckpt.index\n",
      "File exists: gpt2/124M/model.ckpt.index\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.meta gpt2/124M/model.ckpt.meta\n",
      "File exists: gpt2/124M/model.ckpt.meta\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/vocab.bpe gpt2/124M/vocab.bpe\n",
      "File exists: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size='124M', models_dir='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 128])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(8, 128, 128)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dim=-1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.var??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.randn(3); tensor1.shape\n",
    "tensor2 = torch.randn(3)\n",
    "torch.matmul(tensor1, tensor2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.randn(10, 3, 4)\n",
    "tensor2 = torch.randn(4)\n",
    "torch.matmul(tensor1, tensor2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.randn(10, 3, 4)\n",
    "tensor2 = torch.randn(10, 4, 5)\n",
    "torch.matmul(tensor1, tensor2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.randn(10, 3, 4)\n",
    "tensor2 = torch.randn(4)\n",
    "torch.matmul(tensor1, tensor2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 3, 5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.randn(10, 4, 3, 4)\n",
    "tensor2 = torch.randn(10, 4, 4, 5)\n",
    "(tensor1 @ tensor2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [False, False, False,  True,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(10, 10), diagonal=1).bool()[:5, :5]; mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8746, -0.4962,  1.1485, -0.7213, -0.7052],\n",
       "          [-0.3957, -1.2422,  0.7371, -0.6160,  1.7922],\n",
       "          [-2.2315, -0.8595,  1.0116, -1.0823,  0.5964],\n",
       "          [-0.1715,  0.7495,  0.7305, -0.2526, -0.5997],\n",
       "          [ 0.5846, -0.7078, -1.4661,  0.9695,  0.4295]]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = torch.randn(1, 1, 5, 5); attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8746,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-0.3957, -1.2422,    -inf,    -inf,    -inf],\n",
       "          [-2.2315, -0.8595,  1.0116,    -inf,    -inf],\n",
       "          [-0.1715,  0.7495,  0.7305, -0.2526,    -inf],\n",
       "          [ 0.5846, -0.7078, -1.4661,  0.9695,  0.4295]]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores.masked_fill_(mask, -torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_l = torch.tril(torch.ones(10, 10))[:5, :5]\n",
    "mask_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.2596,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-0.5895, -1.4847,    -inf,    -inf,    -inf],\n",
       "          [-1.2648,  0.4248,  0.0476,    -inf,    -inf],\n",
       "          [-0.4809,  0.1451, -3.1990,  0.3704,    -inf],\n",
       "          [ 0.7145,  0.7502, -0.0951,  0.1211,  0.1435]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores_l = torch.randn(1, 1, 5, 5)\n",
    "attn_scores_l.masked_fill_(mask_l==0, -torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "softmax(input, dim, *, dtype=None) -> Tensor\n",
      "\n",
      "Alias for :func:`torch.nn.functional.softmax`.\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.softmax??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7100, 0.2900, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0987, 0.5347, 0.3666, 0.0000, 0.0000],\n",
      "          [0.1894, 0.3543, 0.0125, 0.4438, 0.0000],\n",
      "          [0.2779, 0.2880, 0.1237, 0.1535, 0.1570]]]]) tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0142, 0.4143, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1410, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5061, 0.0179, 0.6340, 0.0000],\n",
      "          [0.3970, 0.0000, 0.1767, 0.2193, 0.2243]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.softmax(attn_scores_l, dim=-1); a\n",
    "dropout = nn.Dropout(0.3)\n",
    "print(a, dropout(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9022857142857144"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6316 * (1.0 / 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # transpose (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        # dot product for each head\n",
    "        attn_scores = torch.matmul(queries, keys.transpose(2, 3)) # (b, num_heads, num_tokens, num_tokens) # double check this\n",
    "        mask = self.mask[:num_tokens, :num_tokens].bool()\n",
    "        attn_scores.masked_fill_(mask, -torch.inf)\n",
    "\n",
    "        scaled_attn_scores = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        scaled_attn_scores = self.dropout(scaled_attn_scores)\n",
    "\n",
    "        # (b, num_heads, num_tokens, num_tokens) * \n",
    "        # (b, num_heads, num_tokens, head_dim) -> (b, num_heads, num_tokens, head_dim) -> (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (scaled_attn_scores @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    '''\n",
    "    Apply LN and residual connection.\n",
    "    '''\n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        # self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        # self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        # self.drop_resid = nn.Dropout(cfg['drop_rate'])\n",
    "        self.sublayer1 = SublayerConnection(cfg['emb_dim'], cfg['drop_rate'])\n",
    "        self.sublayer2 = SublayerConnection(cfg['emb_dim'], cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # might have some interesting consequences when we load weights\n",
    "        # attention block\n",
    "        x = self.sublayer1(x, self.att)\n",
    "        # FF block\n",
    "        x = self.sublayer2(x, self.ff)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        self.final_ln = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds # [batch_size, seq_len, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_ln(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4\n"
     ]
    }
   ],
   "source": [
    "l = [1, 2, 3, 4]\n",
    "def f(a, b, c, d):\n",
    "    print(a, b, c, d)\n",
    "\n",
    "f(*l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 12]), torch.Size([10]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb = nn.Embedding(10, 12)\n",
    "pos_emb\n",
    "a = torch.arange(10); a\n",
    "pos_emb(a).shape, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4487, -0.3829, -0.5809])\n",
      "tensor([[-0.4558,  0.8086,  0.1959,  2.0525, -0.9123, -0.2903, -0.0655,  0.1554,\n",
      "         -0.0462,  1.4487],\n",
      "        [ 0.2075,  0.2069, -0.9391, -1.1859,  1.2251, -2.2263, -1.0860, -1.3618,\n",
      "          0.1457, -0.3829],\n",
      "        [-0.7094, -0.5029, -1.3704,  0.9650,  0.1601,  1.4430,  1.4806,  1.2626,\n",
      "          0.5666, -0.5809]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, 10)\n",
    "print(a[:, -1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (B, T) array of indices in current context\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # (B, T, vocab_size)\n",
    "        \n",
    "        logits = logits[:, -1, :] # (batch, vocab_size)\n",
    "        idx_next = torch.argmax(logits, dim=1, keepdim=True) # (batch, 1)\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (batch, n_tokens+1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(10, 4)\n",
    "b = torch.randn(10, 1)\n",
    "c = torch.cat((a,b), dim=-1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch, Left: {left.shape}, right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    tokens = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(tokens.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 768)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['wpe'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50257, 768)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['wte'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 2304)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['blocks'][0]['attn']['c_attn']['w'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 768), (768, 768), (768, 768))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = params['blocks'][0]['attn']['c_attn']['w']\n",
    "q, k, v = np.split(a, 3, axis=-1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['blocks'][0]['attn']['c_attn']['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768,), (768,), (768,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = params['blocks'][0]['attn']['c_attn']['b']\n",
    "q, k, v = np.split(a, 3, axis=0)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['c_attn', 'c_proj'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['blocks'][0]['attn'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['blocks'][0]['attn']['c_proj']['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attn', 'ln_1', 'ln_2', 'mlp'])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['blocks'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 3072), (3072,))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['blocks'][0]['mlp']['c_fc']['w'].shape, params['blocks'][0]['mlp']['c_fc']['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3072, 768), (768,))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['blocks'][0]['mlp']['c_proj']['w'].shape, params['blocks'][0]['mlp']['c_proj']['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768,), (768,))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['blocks'][0]['ln_1']['g'].shape, params['blocks'][0]['ln_1']['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_into_gpt(gpt: GPTModel, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params['blocks'])):\n",
    "        # Multi head Attention layer\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            params['blocks'][b]['attn']['c_attn']['w'], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T\n",
    "        )\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            params['blocks'][b]['attn']['c_attn']['b'], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params['blocks'][b]['attn']['c_proj']['w'].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params['blocks'][b]['attn']['c_proj']['b']\n",
    "        )\n",
    "\n",
    "        # FF layer\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params['blocks'][b]['mlp']['c_fc']['w'].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params['blocks'][b]['mlp']['c_fc']['b']\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params['blocks'][b]['mlp']['c_proj']['w'].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params['blocks'][b]['mlp']['c_proj']['b']\n",
    "        )\n",
    "\n",
    "        # Norm layers\n",
    "        gpt.trf_blocks[b].sublayer1.norm.scale = assign(\n",
    "            gpt.trf_blocks[b].sublayer1.norm.scale,\n",
    "            params['blocks'][b]['ln_1']['g']\n",
    "        )\n",
    "        gpt.trf_blocks[b].sublayer1.norm.shift = assign(\n",
    "            gpt.trf_blocks[b].sublayer1.norm.shift,\n",
    "            params['blocks'][b]['ln_1']['b']\n",
    "        )\n",
    "        gpt.trf_blocks[b].sublayer2.norm.scale = assign(\n",
    "            gpt.trf_blocks[b].sublayer2.norm.scale,\n",
    "            params['blocks'][b]['ln_2']['g']\n",
    "        )\n",
    "        gpt.trf_blocks[b].sublayer2.norm.shift = assign(\n",
    "            gpt.trf_blocks[b].sublayer2.norm.shift,\n",
    "            params['blocks'][b]['ln_2']['b']\n",
    "        )\n",
    "\n",
    "        # Final norm and output layer weight\n",
    "        gpt.final_ln.scale = assign(gpt.final_ln.scale, params['g'])\n",
    "        gpt.final_ln.shift = assign(gpt.final_ln.shift, params['b'])\n",
    "        gpt.out_head.weight = assign(gpt.out_head.weight, params['wte'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50257, 768)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['wte'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gpt_model import GPTModel, load_weights_into_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids('Every effort moves you', tokenizer),\n",
    "    max_new_tokens=150,\n",
    "    context_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'drop_rate': 0.0,\n",
       " 'qkv_bias': True,\n",
       " 'emb_dim': 768,\n",
       " 'n_layers': 12,\n",
       " 'n_heads': 12}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHOOSE_MODEl = 'gpt2-small (124M)'\n",
    "INPUT_PROMPT = 'Evert effort moves'\n",
    "BASE_CONFIG = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 1024,\n",
    "    'drop_rate': 0.0,\n",
    "    'qkv_bias': True\n",
    "}\n",
    "model_configs = {\n",
    "    'gpt2-small (124M)': {'emb_dim': 768, 'n_layers': 12, 'n_heads': 12},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "BASE_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'124M'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.gpt_download import download_and_load_gpt2\n",
    "from utils.gpt_model import GPTModel, load_weights_into_gpt, generate_text_simple, text_to_token_ids, token_ids_to_text\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/checkpoint gpt2/124M/checkpoint\n",
      "File exists: gpt2/124M/checkpoint\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/encoder.json gpt2/124M/encoder.json\n",
      "File exists: gpt2/124M/encoder.json\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/hparams.json gpt2/124M/hparams.json\n",
      "File exists: gpt2/124M/hparams.json\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.data-00000-of-00001 gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File exists: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.index gpt2/124M/model.ckpt.index\n",
      "File exists: gpt2/124M/model.ckpt.index\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.meta gpt2/124M/model.ckpt.meta\n",
      "File exists: gpt2/124M/model.ckpt.meta\n",
      "https://openaipublic.blob.core.windows.net/gpt-2/models/124M/vocab.bpe gpt2/124M/vocab.bpe\n",
      "File exists: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids('Every effort moves you', tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Is the following text 'spam'? Answer with 'yes' or 'no':\n",
      "    'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "    Answer with 'yes' or 'no'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_2 = \"\"\"\n",
    "    Is the following text 'spam'? Answer with 'yes' or 'no':\n",
    "    'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
    "    Answer with 'yes' or 'no'.\n",
    "\"\"\"\n",
    "print(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Is the following text 'spam'? Answer with 'yes' or 'no':\n",
      "    'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "    Answer with 'yes' or 'no'.\n",
      "     Answer with 'yes' or 'no'.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_ln): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = nn.Linear(in_features=BASE_CONFIG['emb_dim'], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_ln): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0147,  0.0012, -0.0179,  ...,  0.0328,  0.0257, -0.0029],\n",
      "        [-0.0199, -0.0141, -0.0143,  ...,  0.0034, -0.0034,  0.0187]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0140, -0.0182], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_ln.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "params = 0\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        params += 1\n",
    "        \n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"How are you doing\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5117,  1.3087],\n",
      "         [-1.5094,  5.3561],\n",
      "         [-2.8333,  6.0698],\n",
      "         [-2.5524,  4.5580]]])\n",
      "torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(inputs)\n",
    "\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = output[-1, :, :]\n",
    "label = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :] # (batch_size, 2)\n",
    "\n",
    "            predicted_labels = torch.argmax(logits, dim=-1) # (batch_size)\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    accuracy = (correct_predictions / num_examples) * 100\n",
    "    return f'{accuracy:.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.52 53.02 50.33\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "valid_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(train_accuracy, valid_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8, 2])\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1])\n",
      "tensor(0.6363, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for input_batch, label_batch in train_loader:\n",
    "    # print(input_batch.to(device))\n",
    "    print(label_batch.shape)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    print(logits.shape)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, label_batch)\n",
    "    print(label_batch)\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = F.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    loss = 0.0\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        # print(input_batch.shape, target_batch.shape)\n",
    "        if i < num_batches:\n",
    "            loss_batch = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss += loss_batch.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return loss / num_batches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7559135258197784"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_loss_loader(train_loader, model, device, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.833\n",
      "valid loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, 5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, 5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, 5)\n",
    "\n",
    "print(f\"Train loss: {train_loss:.3f}\")\n",
    "print(f\"valid loss: {val_loss:.3f}\")\n",
    "print(f'Test loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune the model to improve the loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional eval step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Epoch {epoch + 1} step {global_step:06d}, train_loss: {train_loss:.3f}, val_loss: {val_loss:.3f}\")\n",
    "            \n",
    "        \n",
    "        # calculate accuracy after evrry epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "        print(f\"train accuracy: {train_accuracy}, val_accuracy: {val_accuracy}\")\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([p for p in model.parameters() if p.requires_grad==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 step 000000, train_loss: 2.153, val_loss: 2.392\n",
      "Epoch 1 step 000050, train_loss: 0.617, val_loss: 0.637\n",
      "Epoch 1 step 000100, train_loss: 0.523, val_loss: 0.557\n",
      "train accuracy: 70.00, val_accuracy: 72.50\n",
      "Epoch 2 step 000150, train_loss: 0.561, val_loss: 0.489\n",
      "Epoch 2 step 000200, train_loss: 0.419, val_loss: 0.397\n",
      "Epoch 2 step 000250, train_loss: 0.409, val_loss: 0.353\n",
      "train accuracy: 82.50, val_accuracy: 85.00\n",
      "Epoch 3 step 000300, train_loss: 0.333, val_loss: 0.320\n",
      "Epoch 3 step 000350, train_loss: 0.340, val_loss: 0.306\n",
      "train accuracy: 90.00, val_accuracy: 90.00\n",
      "Epoch 4 step 000400, train_loss: 0.136, val_loss: 0.200\n",
      "Epoch 4 step 000450, train_loss: 0.153, val_loss: 0.132\n",
      "Epoch 4 step 000500, train_loss: 0.222, val_loss: 0.137\n",
      "train accuracy: 100.00, val_accuracy: 97.50\n",
      "Epoch 5 step 000550, train_loss: 0.207, val_loss: 0.143\n",
      "Epoch 5 step 000600, train_loss: 0.083, val_loss: 0.074\n",
      "train accuracy: 100.00, val_accuracy: 97.50\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 5.41 mins\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "train_duration = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {train_duration:.2f} mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 13)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_losses), len(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_accs), len(val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 8, 1045)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), train_loader.batch_size, len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 * 130)/50 # length of loss array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 5200)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_seen, (130 * 8 * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.3333, 1.6667, 2.0000, 2.3333, 2.6667, 3.0000, 3.3333, 3.6667,\n",
       "        4.0000, 4.3333, 4.6667, 5.0000])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(1, num_epochs, len(train_losses))\n",
    "epochs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 4.3425e+02, 8.6750e+02, 1.3008e+03, 1.7340e+03, 2.1672e+03,\n",
       "        2.6005e+03, 3.0338e+03, 3.4670e+03, 3.9002e+03, 4.3335e+03, 4.7668e+03,\n",
       "        5.2000e+03])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_seen_tensor = torch.linspace(1, examples_seen, len(train_losses))\n",
    "examples_seen_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.1533882856369018,\n",
       "  0.6170469045639038,\n",
       "  0.5231329202651978,\n",
       "  0.5605324864387512,\n",
       "  0.41897520422935486,\n",
       "  0.4089104652404785,\n",
       "  0.3334148287773132,\n",
       "  0.34001914858818055,\n",
       "  0.13633509427309037,\n",
       "  0.15311724469065666,\n",
       "  0.2223953664302826,\n",
       "  0.2065546702593565,\n",
       "  0.083228659350425],\n",
       " 13,\n",
       " torch.Size([13]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses, len(train_losses), examples_seen_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "\n",
    "    ax1.plot(epochs, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny() # create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0) # invisible plot\n",
    "    ax2.set_xlabel('Examples seen')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(1, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(1, examples_seen, len(train_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.3008e+03, 2.6005e+03, 3.9002e+03, 5.2000e+03])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_seen_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_values(epochs_tensor, examples_seen_tensor, [float(p) for p in train_accs], [float(p) for p in val_accs], label='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72.5, 85.0, 90.0, 97.5, 97.5]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[float(p) for p in val_accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('97.21', '97.32', '95.67')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute accuracy over the whole dataset\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "train_accuracy, val_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LLM as spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (sublayer1): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (sublayer2): SublayerConnection(\n",
      "        (norm): LayerNorm()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_ln): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pos_emb.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0] # mistake in original implementation\n",
    "\n",
    "    if max_length is None:\n",
    "        max_length = supported_context_length\n",
    "    else:\n",
    "        max_length = min(max_length, supported_context_length)\n",
    "\n",
    "    input_ids = input_ids[:max_length]\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    # print(input_ids)\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :] # logits of last output token Shape should be (1, 2)\n",
    "    \n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    return 'not spam' if predicted_label == 0 else 'spam', logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('not spam', tensor([[ 3.7726, -2.6696]]))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1 = 'How are you doing'\n",
    "\n",
    "classify_review(text_1, model, tokenizer, device, max_length=train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('not spam', tensor([[ 2.5016, -1.4145]]))\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spam', tensor([[0.3936, 0.8904]]))\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'spam_review_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load('spam_review_classifier.pth')\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length is quite important, having too many padding tokens will lead all inputs to be classified as spam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
